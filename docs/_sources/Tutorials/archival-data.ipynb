{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "g5QkzS-q8YlP",
      "metadata": {
        "id": "g5QkzS-q8YlP"
      },
      "source": [
        "# Data Reduction (archival)\n",
        "\n",
        "This tutorial will guide you through the process of finding, downloading, and reducing data from the Mikulski Archive for Space Telescopes (MAST) to create science-ready light curves. We'll primarily use the `lightkurve` Python package, a powerful tool for working with space telescope data like TESS, Kepler, and K2.\n",
        "\n",
        "**Goal:** By the end of this tutorial, you'll be able to search for space telescope data, download it, perform basic reduction steps (like cleaning and normalization), and generate a light curve ready for analysis (e.g., searching for exoplanet transits or stellar variability).\n",
        "\n",
        "**Environment:** This notebook is designed to work well in online Python IDEs like Google Colab or MS Visual Studio Code with a Python kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "krZZxpJY8YlS",
      "metadata": {
        "id": "krZZxpJY8YlS"
      },
      "source": [
        "## Introduction to MAST and Lightkurve\n",
        "\n",
        "### What is MAST?\n",
        "The **Mikulski Archive for Space Telescopes (MAST)** is NASA's primary archive for optical and ultraviolet astronomical data, with a strong focus on exoplanet-finding missions. It hosts data from missions like:\n",
        "* **TESS (Transiting Exoplanet Survey Satellite):** Currently surveying most of the sky for nearby transiting exoplanets.\n",
        "* **Kepler/K2:** Famous for discovering thousands of exoplanets using the transit method.\n",
        "* Hubble Space Telescope (HST), GALEX, and others.\n",
        "\n",
        "You can explore MAST visually via its portal: [https://mast.stsci.edu](https://mast.stsci.edu)\n",
        "\n",
        "### What is Lightkurve?\n",
        "**Lightkurve** is an open-source Python package designed to simplify the analysis of time-series astronomical data, especially from NASA's TESS, Kepler, and K2 missions. It provides tools for searching, downloading, processing, and plotting light curves and target pixel files (TPFs).\n",
        "\n",
        "Official documentation: [https://docs.lightkurve.org](https://docs.lightkurve.org)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "X02DUtvo8YlS",
      "metadata": {
        "id": "X02DUtvo8YlS"
      },
      "source": [
        "## Setting up Your Python Environment\n",
        "\n",
        "To use `lightkurve`, you'll need Python and several packages including `astropy`, `numpy`, and `matplotlib`. The easiest way to install `lightkurve` and its dependencies is using `pip`. If you are in an environment like Google Colab, this command will install it into your current session.\n",
        "\n",
        "```python\n",
        "!pip install lightkurve\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2aBz2Gyq8YlT",
      "metadata": {
        "id": "2aBz2Gyq8YlT"
      },
      "source": [
        "Now, let's import `lightkurve` and other useful packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8lBXE5Wp8YlT",
      "metadata": {
        "id": "8lBXE5Wp8YlT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\satur\\anaconda3\\Lib\\site-packages\\lightkurve\\prf\\__init__.py:7: UserWarning: Warning: the tpfmodel submodule is not available without oktopus installed, which requires a current version of autograd. See #1452 for details.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import lightkurve as lk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline;\n",
        "# This ensures plots appear inline in Jupyter notebooks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pCJS4_rR8YlU",
      "metadata": {
        "id": "pCJS4_rR8YlU"
      },
      "source": [
        "## Searching for Data on MAST\n",
        "\n",
        "`lightkurve` allows you to search for data programmatically. You can search by target name, mission-specific ID (like TIC for TESS, KIC for Kepler, EPIC for K2), or coordinates.\n",
        "\n",
        "Let's search for data for the star **π Mensae (pi Men)**, a bright star known to host exoplanets, observed by TESS. Its TESS Input Catalog (TIC) ID is 261136679."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EBUuHkck8YlU",
      "metadata": {
        "id": "EBUuHkck8YlU"
      },
      "outputs": [],
      "source": [
        "target_star = \"pi Men\"\n",
        "# You can also use target_star = \"TIC 261136679\"\n",
        "# Or for Kepler: target_star = \"KIC 8462852\" (Boyajian's Star)\n",
        "# Or for K2: target_star = \"EPIC 201367065\"\n",
        "\n",
        "search_result = lk.search_lightcurve(target_star)\n",
        "search_result # Display the search results as a table"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "csjr7Jv_8YlU",
      "metadata": {
        "id": "csjr7Jv_8YlU"
      },
      "source": [
        "The `search_result` object is a table listing all available light curve products for your target. It includes information like the mission, sector/quarter/campaign, author (pipeline), and an observation ID.\n",
        "\n",
        "You can filter these results. For example, if you only want TESS data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VYh-iL2p8YlV",
      "metadata": {
        "id": "VYh-iL2p8YlV"
      },
      "outputs": [],
      "source": [
        "search_tess = lk.search_lightcurve(target_star, mission=\"TESS\")\n",
        "search_tess"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mYMbfNtF8YlV",
      "metadata": {
        "id": "mYMbfNtF8YlV"
      },
      "source": [
        "You can also search for Target Pixel Files (TPFs), which contain the raw pixel data around your target. This is useful if you want to perform custom photometry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RYaWh_qn8YlW",
      "metadata": {
        "id": "RYaWh_qn8YlW"
      },
      "outputs": [],
      "source": [
        "search_tpf_result = lk.search_targetpixelfile(target_star, mission=\"TESS\")\n",
        "search_tpf_result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YkcuzP0T8YlW",
      "metadata": {
        "id": "YkcuzP0T8YlW"
      },
      "source": [
        "## Understanding Data Products and Downloading Data\n",
        "\n",
        "MAST provides several types of data products:\n",
        "* **Light Curve Files (LCFs):** These files contain pre-processed light curves. For TESS and Kepler, common flux types include:\n",
        "    * `SAP_FLUX` (Simple Aperture Photometry): Sum of flux in an optimal aperture. Can be affected by instrument systematics.\n",
        "    * `PDCSAP_FLUX` (Pre-search Data Conditioning SAP Flux): SAP flux corrected for instrumental systematics. This is usually the best starting point for transit searches or stellar variability studies.\n",
        "* **Target Pixel Files (TPFs):** These files contain the time-series of images (pixel data) centered on the target star. You can use TPFs to define your own photometric aperture and extract a light curve.\n",
        "\n",
        "Let's download the available TESS light curves for π Mensae. The `download_all()` method can be used on a search result to get all matching datasets. You can also download specific datasets by indexing the search result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bAE3xYPS8YlW",
      "metadata": {
        "id": "bAE3xYPS8YlW"
      },
      "outputs": [],
      "source": [
        "# Download all TESS light curves for pi Men processed by the SPOC pipeline\n",
        "# We select the SPOC pipeline products as they are typically the most robust for TESS\n",
        "lc_collection = search_tess[search_tess.author == \"SPOC\"].download_all()\n",
        "lc_collection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wTrk09738YlW",
      "metadata": {
        "id": "wTrk09738YlW"
      },
      "source": [
        "`lc_collection` is a `LightCurveCollection` object, which is a list of `LightCurve` objects. Let's inspect the first light curve in the collection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VPkTcFs88YlW",
      "metadata": {
        "id": "VPkTcFs88YlW"
      },
      "outputs": [],
      "source": [
        "if lc_collection:\n",
        "    lc0 = lc_collection[0]\n",
        "    print(lc0)\n",
        "    lc0.plot();\n",
        "else:\n",
        "    print(f\"No light curves found for {target_star} with the specified criteria.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E2vT-zNZ8YlW",
      "metadata": {
        "id": "E2vT-zNZ8YlW"
      },
      "source": [
        "The plot shows time on the x-axis and flux (usually `PDCSAP_FLUX` by default for `lk.LightCurve` objects from SPOC) on the y-axis. You can specify which flux column to plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7BxFji3L8YlW",
      "metadata": {
        "id": "7BxFji3L8YlW"
      },
      "outputs": [],
      "source": [
        "if lc_collection:\n",
        "    # lc0.plot(column='sap_flux', label='SAP Flux')\n",
        "    lc0.plot(column='pdcsap_flux', label='PDCSAP Flux');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8J0DyCvB8YlW",
      "metadata": {
        "id": "8J0DyCvB8YlW"
      },
      "source": [
        "## Working with Light Curve Files (LCFs)\n",
        "\n",
        "A `LightCurve` object has several useful attributes and methods.\n",
        "* `lc.time`: Time values (often in BJD - Barycentric Julian Date).\n",
        "* `lc.flux`: Flux values.\n",
        "* `lc.flux_err`: Errors on flux values.\n",
        "* `lc.quality`: Quality flags indicating potential issues with data points.\n",
        "\n",
        "### Stitching Multiple Sectors/Quarters\n",
        "If your target was observed in multiple TESS sectors or Kepler quarters, `lc_collection.stitch()` can combine them. It's often a good idea to normalize each segment before stitching to handle brightness offsets between them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rqlgd7BW8YlX",
      "metadata": {
        "id": "rqlgd7BW8YlX"
      },
      "outputs": [],
      "source": [
        "if len(lc_collection) > 1:\n",
        "    # Stitching can sometimes introduce edge effects or fail if sectors are very different.\n",
        "    # Normalizing each light curve before stitching helps with offsets.\n",
        "    stitched_lc = lc_collection.stitch(corrector_func=lambda lc: lc.normalize().remove_nans())\n",
        "elif lc_collection: # Only one sector/quarter\n",
        "    stitched_lc = lc_collection[0].normalize().remove_nans()\n",
        "else:\n",
        "    print(\"No light curves to stitch.\")\n",
        "\n",
        "if 'stitched_lc' in locals() and stitched_lc is not None:\n",
        "    stitched_lc.plot(label=\"Stitched & Normalized Light Curve\");\n",
        "elif lc_collection and lc_collection[0] is not None: # Fallback if stitching failed or only one LC\n",
        "    print(\"Plotting first downloaded light curve (normalized and NaNs removed).\")\n",
        "    stitched_lc = lc_collection[0].normalize().remove_nans() # Ensure stitched_lc exists for next steps\n",
        "    stitched_lc.plot(label=\"Single Sector Normalized Light Curve\");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tqrYzSHm8YlX",
      "metadata": {
        "id": "tqrYzSHm8YlX"
      },
      "source": [
        "### Data Cleaning with Quality Flags\n",
        "Space telescope data often have quality flags indicating issues like cosmic ray hits, spacecraft manoeuvres, or bad pixels. `lightkurve` attempts to handle standard quality masking when loading data (especially for `PDCSAP_FLUX` which often has NaNs where corrections failed).\n",
        "\n",
        "We've already used `remove_nans()` which is crucial for `PDCSAP_FLUX`. Another common step is sigma clipping for remaining outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_H0Wdf9o8YlX",
      "metadata": {
        "id": "_H0Wdf9o8YlX"
      },
      "outputs": [],
      "source": [
        "if 'stitched_lc' in locals() and stitched_lc is not None:\n",
        "    # Remove outliers using sigma clipping\n",
        "    # This removes points that are more than, e.g., 5 standard deviations from the median\n",
        "    # It's often better to do this after some initial detrending if strong systematics are present.\n",
        "    cleaned_lc = stitched_lc.remove_outliers(sigma=5)\n",
        "\n",
        "    print(f\"Points before sigma clipping: {len(stitched_lc.flux)}\")\n",
        "    print(f\"Points after sigma clipping: {len(cleaned_lc.flux)}\")\n",
        "\n",
        "    cleaned_lc.plot(label=\"Cleaned & Clipped Light Curve\");\n",
        "else:\n",
        "    print(\"Stitched light curve not available for cleaning.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-wa1htkN8YlX",
      "metadata": {
        "id": "-wa1htkN8YlX"
      },
      "source": [
        "### Normalization and Detrending\n",
        "**Normalization** typically means dividing the flux by its median (or mean) value, so the baseline flux is around 1.0. This is useful for comparing depths of transits or variability.\n",
        "**Detrending** aims to remove instrumental systematics or stellar activity trends that are not of primary interest (e.g., if you're looking for transits, you might want to remove long-term stellar variability).\n",
        "\n",
        "`lightkurve` offers several detrending methods. A common one is `flatten()`, which applies a Savitzky-Golay filter to remove low-frequency variations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GPT850IG8YlX",
      "metadata": {
        "id": "GPT850IG8YlX"
      },
      "outputs": [],
      "source": [
        "if 'cleaned_lc' in locals() and cleaned_lc is not None:\n",
        "    # Our cleaned_lc is already normalized from the stitching step.\n",
        "    # If you started with a raw light curve: normalized_lc = raw_lc.normalize()\n",
        "\n",
        "    # Detrending with flatten\n",
        "    # window_length should be chosen carefully: odd number, typically several times larger than the event of interest (e.g., transit duration)\n",
        "    # but smaller than long-term trends you want to remove.\n",
        "    # For TESS 2-minute cadence data of π Mensae c (P ~ 6.27 days, transit duration ~3.2 hours):\n",
        "    # Transit duration in points: (3.2 hours * 60 min/hour) / 2 min/point = ~96 points.\n",
        "    # A window_length of e.g. 5 * 96 + 1 = 481 (must be odd) might be a starting point.\n",
        "    # This needs to be tuned based on the specific light curve and science goal.\n",
        "    try:\n",
        "        flat_lc = cleaned_lc.flatten(window_length=481, polyorder=3)\n",
        "        flat_lc.plot(label=\"Flattened Light Curve\");\n",
        "    except Exception as e:\n",
        "        print(f\"Error during flatten: {e}. The light curve might be too short or have issues.\")\n",
        "        print(\"Using the cleaned (but not flattened) light curve for subsequent steps.\")\n",
        "        flat_lc = cleaned_lc # Fallback to unflattened if flatten fails\n",
        "        flat_lc.plot(label=\"Cleaned (Unflattened) Light Curve\");\n",
        "\n",
        "else:\n",
        "    print(\"Cleaned light curve not available for detrending.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QUKA-USA8YlX",
      "metadata": {
        "id": "QUKA-USA8YlX"
      },
      "source": [
        "## Working with Target Pixel Files (TPFs) - Custom Photometry\n",
        "\n",
        "If pre-processed light curves are not suitable (e.g., due to contamination from nearby stars, or if you want to experiment with different apertures), you can create your own light curve from TPF data.\n",
        "\n",
        "First, download a TPF. Let's use the `search_tpf_result` from earlier and download one TPF for π Mensae."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Heqar-Q38YlX",
      "metadata": {
        "id": "Heqar-Q38YlX"
      },
      "outputs": [],
      "source": [
        "# We'll select the first TPF from the TESS SPOC pipeline results\n",
        "tpf_search_spoc = search_tpf_result[(search_tpf_result.author == \"SPOC\") & (search_tpf_result.mission == \"TESS\")]\n",
        "if len(tpf_search_spoc) > 0:\n",
        "    print(f\"Found {len(tpf_search_spoc)} TPFs. Downloading the first one.\")\n",
        "    tpf = tpf_search_spoc[0].download()\n",
        "    tpf.plot(frame=0); # Plot the first frame of the TPF\n",
        "else:\n",
        "    print(f\"No TPFs found for {target_star} from TESS SPOC pipeline.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BkhAmElg8YlX",
      "metadata": {
        "id": "BkhAmElg8YlX"
      },
      "source": [
        "The plot shows the pixel data. The red outline is the default pipeline aperture. You can define your own aperture interactively (in a Jupyter Notebook session by enabling `tpf.interact()`) or by creating a boolean mask programmatically.\n",
        "\n",
        "### Creating a Custom Aperture Mask\n",
        "Let's try to define a simple circular aperture or use a threshold mask. For this example, we'll use the pipeline's default aperture, which is often a good choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mZ-8slR08YlX",
      "metadata": {
        "id": "mZ-8slR08YlX"
      },
      "outputs": [],
      "source": [
        "if 'tpf' in locals() and tpf is not None:\n",
        "    # Using the pipeline-defined aperture mask\n",
        "    pipeline_aperture = tpf.pipeline_mask\n",
        "    tpf.plot(aperture_mask=pipeline_aperture, mask_color='red');\n",
        "    print(f\"Pipeline aperture mask sum (pixels): {pipeline_aperture.sum()}\")\n",
        "\n",
        "    # To create a custom threshold mask (alternative):\n",
        "    # custom_aperture = tpf.create_threshold_mask(threshold=5) # threshold in sigma above median\n",
        "    # tpf.plot(aperture_mask=custom_aperture, mask_color='blue');\n",
        "    # print(f\"Custom threshold aperture mask sum (pixels): {custom_aperture.sum()}\")\n",
        "else:\n",
        "    print(\"TPF not available for aperture definition.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uqPbGXYn8YlX",
      "metadata": {
        "id": "uqPbGXYn8YlX"
      },
      "source": [
        "### Performing Aperture Photometry\n",
        "Once you have an aperture mask, you can extract the light curve using the `to_lightcurve()` method. This method will sum the flux within the aperture for each cadence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wl5_pTxU8YlX",
      "metadata": {
        "id": "wl5_pTxU8YlX"
      },
      "outputs": [],
      "source": [
        "if 'tpf' in locals() and tpf is not None and 'pipeline_aperture' in locals() and pipeline_aperture.sum() > 0:\n",
        "    custom_lc_from_tpf = tpf.to_lightcurve(aperture_mask=pipeline_aperture)\n",
        "    custom_lc_from_tpf.plot(label=\"Light Curve from TPF (Pipeline Aperture)\");\n",
        "else:\n",
        "    print(\"TPF or suitable aperture mask not available for custom photometry.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nfsH6yLK8YlX",
      "metadata": {
        "id": "nfsH6yLK8YlX"
      },
      "source": [
        "This custom light curve is essentially a SAP (Simple Aperture Photometry) light curve. It will likely contain systematics from the instrument and spacecraft. You would then need to perform systematic correction (e.g., using `Regressors` in `lightkurve`, or methods like CBV, PLD if you delve deeper). For simplicity, we'll skip advanced custom systematic correction here and revert to using the PDCSAP flux from earlier (`flat_lc`) for the transit search example, as it has already undergone some systematic correction."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96pd7MpL8YlY",
      "metadata": {
        "id": "96pd7MpL8YlY"
      },
      "source": [
        "## Example: Finding a Transit\n",
        "\n",
        "Let's take our flattened light curve (`flat_lc`) derived from the pre-processed PDCSAP data and see if we can spot the known transit of π Mensae c (Period ~6.27 days, Duration ~3.2 hours).\n",
        "\n",
        "First, let's phase-fold the light curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XhfZYX458YlY",
      "metadata": {
        "id": "XhfZYX458YlY"
      },
      "outputs": [],
      "source": [
        "if 'flat_lc' in locals() and flat_lc is not None and len(flat_lc.remove_nans()) > 0:\n",
        "    # Known parameters for pi Men c (from NASA Exoplanet Archive or literature)\n",
        "    period_pi_men_c = 6.26835 # days\n",
        "    t0_pi_men_c = 2458353.4626 # BJD, example epoch of transit center\n",
        "\n",
        "    # Phase fold the light curve\n",
        "    folded_lc = flat_lc.fold(period=period_pi_men_c, epoch_time=t0_pi_men_c)\n",
        "    folded_lc.plot(label=f\"Folded on P={period_pi_men_c:.4f} d\");\n",
        "\n",
        "    # To see the transit more clearly, you might want to bin the folded data\n",
        "    binned_folded_lc = folded_lc.bin(time_bin_size=0.005) # Bin size in phase units (e.g., 0.005 is 1/200th of the period)\n",
        "    binned_folded_lc.plot(label=f\"Binned & Folded (P={period_pi_men_c:.4f} d)\", marker='o', linestyle='none');\n",
        "    plt.xlim(-0.05, 0.05) # Zoom in on the transit at phase 0\n",
        "    # Pi Men c transit depth is ~550 ppm = 0.00055 in normalized flux\n",
        "    # So, out-of-transit is 1.0, in-transit minimum is ~1.0 - 0.00055 = 0.99945\n",
        "    plt.ylim(0.9990, 1.0010) # Adjust y-limits based on expected transit depth\n",
        "    plt.title(f\"Phase-folded light curve of {target_star}\")\n",
        "else:\n",
        "    print(\"Flattened light curve not available or is empty for folding.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m-y2tMTd8YlY",
      "metadata": {
        "id": "m-y2tMTd8YlY"
      },
      "source": [
        "This plot should show the characteristic dip of an exoplanet transit around phase 0, assuming the period, T0, and detrending were appropriate. The depth of π Men c is very small (~550 ppm or 0.055%), so it requires good quality data and careful processing. You might need to adjust `window_length` in `flatten` or try other detrending to see it clearly, or it may be more apparent in certain TESS sectors than others."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9hgecnQx8YlY",
      "metadata": {
        "id": "9hgecnQx8YlY"
      },
      "source": [
        "## Saving Your Reduced Light Curve\n",
        "\n",
        "Once you have a processed light curve that you're happy with (e.g., `flat_lc` or `folded_lc`), you can save it to a file. Common formats include CSV or FITS.\n",
        "\n",
        "**Note for Google Colab users:** Files saved this way will be stored in the temporary Colab environment. To save them permanently, you'll need to download them to your local machine or mount your Google Drive and save them there. You can find downloaded files in the file browser panel in Colab (usually on the left sidebar) and right-click to download."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2_uhzfPS8YlY",
      "metadata": {
        "id": "2_uhzfPS8YlY"
      },
      "outputs": [],
      "source": [
        "if 'flat_lc' in locals() and flat_lc is not None and len(flat_lc.remove_nans()) > 0:\n",
        "    # Save the time-series (flattened) light curve as CSV\n",
        "    # Using .to_pandas() to select specific columns and then .to_csv()\n",
        "    output_filename_csv = f\"{target_star.replace(' ', '_')}_flat_lightcurve.csv\"\n",
        "    flat_lc.to_csv(output_filename_csv, overwrite=True)\n",
        "    print(f\"Flattened light curve saved as: {output_filename_csv}\")\n",
        "    # Display the first few lines by reading it back (optional)\n",
        "    # import pandas as pd\n",
        "    # print(pd.read_csv(output_filename_csv).head())\n",
        "\n",
        "    # Save as FITS (Lightkurve's default format includes more metadata)\n",
        "    output_filename_fits = f\"{target_star.replace(' ', '_')}_flat_lightcurve.fits\"\n",
        "    flat_lc.write(output_filename_fits, overwrite=True)\n",
        "    print(f\"Flattened light curve saved as: {output_filename_fits}\")\n",
        "\n",
        "    # If using Google Colab and want to trigger a download for the CSV:\n",
        "    # from google.colab import files\n",
        "    # files.download(output_filename_csv)\n",
        "else:\n",
        "    print(\"No processed light curve to save.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4oGw4bF8YlY",
      "metadata": {
        "id": "f4oGw4bF8YlY"
      },
      "source": [
        "## Conclusion and Further Steps\n",
        "\n",
        "Congratulations! You've learned the basics of:\n",
        "* Searching for data from space telescopes like TESS and Kepler using `lightkurve`.\n",
        "* Understanding the difference between Light Curve Files (LCFs) and Target Pixel Files (TPFs).\n",
        "* Downloading and plotting light curves.\n",
        "* Performing essential data reduction steps: cleaning, normalization, and detrending.\n",
        "* Extracting a custom light curve from TPF data (basic aperture photometry).\n",
        "* Phase-folding a light curve to look for periodic signals like exoplanet transits.\n",
        "* Saving your processed light curve, with considerations for online IDEs.\n",
        "\n",
        "**Further Steps for Your Research:**\n",
        "* **Advanced Detrending:** Explore more sophisticated detrending techniques (e.g., Gaussian Processes, Cotrending Basis Vectors - CBVs, Pixel Level Decorrelation - PLD) if simple methods are insufficient.\n",
        "* **Period Finding:** If the period of a signal is unknown, use period-finding algorithms (e.g., Box Least Squares for transits, Lomb-Scargle periodogram for stellar oscillations) available in `lightkurve` or `astropy.timeseries`.\n",
        "* **Transit Modeling:** If you find a transit, you can model its shape to determine planetary parameters (radius, inclination, etc.) using packages like `exoplanet`, `batman`, or `PyTransit`.\n",
        "* **Systematics Mitigation:** Deep dive into understanding and mitigating instrumental systematics specific to the mission you are working with.\n",
        "* **Consult Documentation:** The [Lightkurve documentation](https://docs.lightkurve.org) is an excellent resource with many tutorials and API references."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
